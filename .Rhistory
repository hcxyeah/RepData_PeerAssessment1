packageVersion("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
install.packages("dplyr")
install.packages("dplyr")
packageVersion("dplyr")
swirl()
swirl()
library(swirl)
swirl()
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
select(cran, -X:size)
-5:20
-5:-20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Conparison
?Comparison
filter(cran, r_version == "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
file(cran, !is.na(r_version) == TRUE)
file(cran, !is.na(cran$r_version) == TRUE)
file(cran, !is.na(cran$r_version))
file(cran, !is.na(r_version))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size/2^20)
mutate(cran3, size_gb = size_mb/2^10)
mutate(cran3, size_gb = size_mb/2^10)
cran3
mutate(cran3, size_mb = size/2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
re(mydf)
rm(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 464)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
arrange(top_unique, desc(unique))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex, class, count, -grade)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, c("sex", "class"))
submit()
submit()
students3
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
?spread()
?spread
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
extract_numeric("class5")
submit()
?mutate
submit()
submit()
students4
submit()
submit()
submit()
submit()
submit()
passed
failed
?mutate
?mutate()
mutate(status = "passed")
mutate(passed, status = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
?bind_rows
bind_rows(passed, failed)
sat
submit()
?separate
submit()
submit()
submit()
submit()
swirl()
library(swirl)
swirl()
Sys.getlocale()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
now()
this_moment <- now()
this_moment
hour(this_day)
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
?now
now(tzone = "America/New_York")
nyc <- now(tzone = "America/New_York")
nyc
nyc + days(2)
depart <- nyc + days(2)
depart
depart <- update(depart, hours(17), minutes(34))
depart <- update(depart, hours = , minutes = 34)
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
interval(last_time, arrive)
?"interval"
?interval
interval(last_time, arrive, tzone = attr(last_time, "Asian/HongKong"))
last_time <- with_tz(last_time, tzone = "Asia/Hong_Kong")
interval(last_time, arrive)
how_long(last_time, arrive)
how_long <- interval(last_time, arrive)
as.period(how_long)
stopwatch()
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
head(pollution)
dim(pollution)
summary(pollution$pm25)
quantile(ppm)
boxplot(ppm, col = "blue")
abline(h = 12)
hist(ppm, col = "green")
rug(ppm)
low
high
hist(ppm, col = "green", breaks = 100)
rug(ppm)
hist(ppm, col = "green")
abline(v = 12, lwd = 2)
abline(v = median(ppm), col = "magenta", lwd = 4)
pollution
names(pollution)
reg <- pollution$region
reg <- table(pollution$region)
reg
barplot(reg, col = "wheat", main = "Number of Counties in Each Region")
boxplot(pollution, col = "red")
boxplot(pm25~region, col = "red")
boxplot(pm25~region, data = polution, col = "red")
boxplot(pm25~region, data = pollution, col = "red")
par(mfrow = c(2,1), mar = c(4,4,2,1))
east <- subset(pollution, region == "east")
head(east)
hist(east$pm25, col = "green")
hist(subset(pollution, region == "east"), col = "green")
hist(subset(pollution, region == "east")$pm25, col = "green")
hist(subset(pollution, region == "west")$pm25, col = "green")
with(pollution, plot(latitude, pm25))
abline(h = 12, lwd = 2, lty = 2)
plot(pollution$latitude, ppm, col = pollution$region)
abline(h = 12, lwd = 2, lty = 2)
par(mfrow = c(1,2), mar = c(5, 4, 2, 1))
west <- subset(pollution, region == "west")
with(west, plot(latitude, pm25, main = "West"))
plot(west$latitude, west$pm25, main = "West")
plot(east$latitude, east$pm25, main = "East")
library(swirl)
swirl()
?Devices
plot(eruption, waiting)
plot(eruptions, waiting)
command(faithful, plot)
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser data")
dev.cur()
pdf(file = "myplot.pdf")
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser data")
dev.cur()
dev.off()
dev.cur()
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser data")
dev.copy(png, "geyserplot.png")
dev.copy(png, file = "geyserplot.png")
dev.off()
head(cars)
with(cars, plot(speed, dist))
text(mean(cars$speed), max(cars$dist), "SWIRL rules")
text(mean(cars$speed), max(cars$dist), "SWIRL rules!")
head(state)
table(state$region)
xyplot(Life.Exp ~ Income | region, state, layout = c(4,1))
xyplot(Life.Exp ~ Income | region, state, layout = c(2,2))
head(mpg)
dim(mpg)
table(mpg$model)
qplot(displ, hwy, mpg)
qplot(displ, hwy, data = mpg)
head(airquality)
range(airquality$Ozone, na.rm = TRUE)
hist(airquality$Ozone)
table(airquality$Month)
boxplot(Ozone~Month, airquality)
install.packages("xlsx")
library(xlsx)
install.packages("rJava")
install.packages("rJava")
install.packages("xlsxjars")
library(xlsx)
library(rJava)
library(xlsxjars)
library(xlsx)
install.packages("rJava", type="source")
install.packages("rJava", type = "source")
library(rJava)
library(xlsxjars)
library(xlsx)
library(rJava)
library(rJava)
install.packages("xlsx")
library(rJava)
JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.7.0_40.jdk/Contents/Home
install.packages("rJava", type = "source")
library(rJava)
library(xlsx)
library(rJava)
Sys.getenv(/Library/Java/JavaVirtualMachines/jdk1.8.0_20.jdk/Contents/Home/jre)
Sys.getenv(JAVA_HOME = /Library/Java/JavaVirtualMachines/jdk1.8.0_20.jdk/Contents/Home/jre)
Sys.getenv(JAVA_HOME = '/Library/Java/JavaVirtualMachines/jdk1.8.0_20.jdk/Contents/Home/jre')
library(rJava)
install.packages("rJava", type = "source")
library(rJava)
Sys.getenv(JAVA_HOME = '/Library/Java/JavaVirtualMachines/jdk1.8.0_20.jdk/Contents/Home/jre')
Sys.getenv("JAVA_HOME")
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_20.jdk/Contents/Home/jre
update.packages()
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", key = "d1409dc3e7ff97f010b4", secret = "917e459ad53b2a7c486c5570c73dbdf7c5b4e9b8")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("readRDS")
?oauth_endpoints
?oauth2.0_token
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./quiz1.csv", method = "curl")
quiz1 <- read.csv("quiz1.csv")
agriculturelogical <- subset(quiz1, c(ACR == 3, AGS==6))
which(agriculturelogical)
agriculturelogical
agriculturelogical <- ACR == 3 & AGS==6
agriculturelogical <- quiz1$ACR == 3 & quiz1$AGS==6
which(agriculturelogical)
install.packages("jpeg")
library(jpeg)
img <- readJPEG(url("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"), native = TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl, destfile = "./quiz3_2.jpg", method = "curl")
img <- readJPEG("quiz3_2.jpg", native = TRUE)
quantile(img, probs = c(.3, .8))
fileUrl1 = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
fileUrl2 = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "./quiz3_3.csv", method = "curl")
download.file(fileUrl2, destfile = "./quiz3_4.csv", method = "curl")
GDP <- read.csv("quiz3_3.csv")
edu <- read.csv("quiz3_4.csv")
names(GDP)
head(GDP)
head(edu)
names(edu)
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all=FALSE)
dim(mergeddata)
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all=TRUE)
dim(mergeddata)
?merge
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all.x=TRUE)
dim(mergeddata)
head(GDP)
dim(GDP)
fileUrl1 = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl1, destfile = "./quiz3_3.csv", method = "curl")
dim(GDP)
head(GDP)
?read.csv
GDP <- read.csv("quiz3_3.csv")
dim(GDP)
head(GDP)
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all.x=TRUE)
dim(mergeddata)
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all=FALSE)
dim(mergeddata)
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all=TURE)
dim(mergeddata)
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all.X=TURE)
dim(mergeddata)
library(plyr)
install.packages("plyr")
install.packages("tplyr")
library(plyr)
arrange(GDP, desc(X))
install.packages("dplyr")
library(dplyr)
head(arrange(GDP, desc(X)))
head(arrange(GDP, desc(X)),20)
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all.X=TURE)
names(mergeddata)
head(arrange(mergeddata, desc(Ranking)),20)
head(arrange(GDP, desc(Ranking)),20)
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all.X=TURE)
mergeddata <- merge(GDP, edu, by.x = "X", by.y = "CountryCode", all.X=TURE, sort = TRUE)
head(mergeddata)
dim(mergeddata)
download.file(fileUrl1, destfile = "./quiz3_3.csv", method = "curl")
GDP <- data.table(read.csv("quiz3_3.csv"))
?data.table
??data.table
library(dplyr)
GDP <- data.table(read.csv("quiz3_3.csv"))
install.packages("data.table")
library(data.table)
GDP <- data.table(read.csv("quiz3_3.csv"))
head(GDP)
GDP <- data.table(read.csv("quiz3_3.csv", skip = 4))
head(GDP)
setnames(GDP, c("X", "X.1", "X.2", "X.3", "X.4"), c("CountryCode", "Ranking", "name", "gdp"))
setnames(GDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "Ranking", "name", "gdp"))
head(GDP)
GDP <- GDP[X != ""]
GDP <- GDP[CountryCode != ""]
dim(GDP)
GDP <- GDP[, list("CountryCode", "Ranking", "name", "gdp)]
GDP <- GDP[, list("CountryCode", "Ranking", "name", "gdp)]
GDP <- GDP[, list("CountryCode", "Ranking", "name", "gdp)]
GDP <- GDP[, list(CountryCode, Ranking, name, gdp)]
dim(GDP)
GDP <- GDP[, list(CountryCode, Ranking, name, gdp)]
li
GDP <- GDP[, list(CountryCode, Ranking, name, gdp)]
getwd
getwd()
setwd("./GitHub/RepData_PeerAssessment1")
data <- read.csv("activity.csv")
head(data)
data$date <- as.Date(data$date, "%Y-%m-%d")
sum(is.na(data$steps))
str(data)
mean(is.na(data$steps))
aggregate(steps~date, data, sum)
total_steps_per_day <- aggregate(steps~date, data, sum)
hist(total_steps_per_day$steps)
# Chunk 1
setwd("./GitHub/RepData_PeerAssessment1")
data <- read.csv("activity.csv")
data$date <- as.Date(data$date, "%Y-%m-%d")
mean(is.na(data$steps))
str(data)
hist(total_steps_per_day$steps, xlab = "Total number of steps per day")
mean_steps <- mean(total_steps_per_day$steps, na.rm = TRUE)
median_steps <- median(total_steps_per_day$steps, na.rm = TRUE)
avg_steps_interval <- aggregate(steps~interval, data, mean, na.rm = TRUE)
avg_steps_interval
head(data, 20)
plot(avg_steps_interval$interval, avg_steps_interval$steps, type = "l")
plot(avg_steps_interval$interval, avg_steps_interval$steps, type = "l", xlab = "interval",
ylab = "Average steps taken")
avg_steps_interval <- aggregate(steps~interval+date, data, mean, na.rm = TRUE)
avg_steps_interval
avg_steps_interval <- aggregate(steps~interval, data, mean, na.rm = TRUE)
max(steps)
max(avg_steps_interval$steps)
which.max(avg_steps_interval$steps)
avg_steps_interval$interval[which.max(avg_steps_interval$steps)]
where_max <- avg_steps_interval$interval[which.max(avg_steps_interval$steps)]
na_num <- sum(is.na(data))
na_num
na_num <- sum(is.na(data$steps))
na_num
?transform
?match
new_data <- transform(data, steps = ifelse(is.na(data$steps),avg_steps_interval[match(data$interval, avg_steps_interval$interval)], data$steps))
new_data <- transform(data, steps = ifelse(is.na(data$steps),avg_steps_interval$steps[match(data$interval, avg_steps_interval$interval)], data$steps))
sum(is.na(new_data))
new_total_per_day <- aggregate(steps~date, new_data, sum)
new_mean <- mean(new_total_per_day$steps, na.rm = TRUE)
new_median <- median(new_total_per_day$steps)
mean_steps
median_steps
new_mean
new_median
new_mean <- mean(new_total_per_day$steps)
new_median <- median(new_total_per_day$steps)
new_median
new_mean
mean_dif <- new_mean - mean_steps
median_dif <- new_median - median_steps
mean_dif
median_dif
?weekdays
weekdays(data$date[1])
new_data$weekday <- ifelse(weekdays(new_data$date) %in% c("Saturday", "Sunday"), "weekday", "weekend")
head(new_data)
aggregate(steps~interval+weekday, new_data, mean)
avg_interval_weekday <- aggregate(steps~interval+weekday, new_data, mean)
library(ggplot2)
ggplot(avg_interval_weekday, aes(interval, steps, col = weekday)) +
geom_line()
getwd()
getwd()
install.packages("knitr")
install.packages("knitr")
getwd()
